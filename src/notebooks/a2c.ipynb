{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25dde08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import accumulate\n",
    "from typing import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from cycler import cycler\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0409c400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5ecddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_GAMMA = 1.0\n",
    "REWARD_STEPS = 0\n",
    "\n",
    "GLOVE_DIM = 300\n",
    "TRAIN_SIZE = \"md\"\n",
    "TEST_SIZE = \"sm\"\n",
    "\n",
    "EMBED_DIM = GLOVE_DIM\n",
    "LSTM_LAYERS = 1\n",
    "LSTM_H_DIM = EMBED_DIM\n",
    "RNET_DROPOUT = 0.5\n",
    "\n",
    "ENV_GAMMA = 0.1\n",
    "\n",
    "PGN_LR = 0.005\n",
    "RNET_LR = 0.001\n",
    "SRM_LR = 0.001\n",
    "\n",
    "PGN_CLIP_GRAD = 0.0\n",
    "ENTROPY_BETA = 0.001\n",
    "\n",
    "PRETRAIN_SRM_RNET_EPOCHS = 200\n",
    "PRETRAIN_PGN_EPOCHS = 100\n",
    "\n",
    "EPISODES_BATCH = 10\n",
    "PRETRAIN_SRM_RNET_BATCH = EPISODES_BATCH\n",
    "\n",
    "FEATURES = \"\"\n",
    "COMMENTS = \"\"\n",
    "\n",
    "EXPERIMENT_NAME = \"15_04_2\"\n",
    "\n",
    "EPOCHS = 500\n",
    "EVAL_PERIOD = 10\n",
    "LOG_PERIOD = EVAL_PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b362ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_hyperparameters() -> dict:\n",
    "    return {\n",
    "        \"RL_GAMMA\": RL_GAMMA,\n",
    "        \"REWARD_STEPS\": REWARD_STEPS,\n",
    "        \"GLOVE_DIM\": GLOVE_DIM,\n",
    "        \"TRAIN_SIZE\": TRAIN_SIZE,\n",
    "        \"TEST_SIZE\": TEST_SIZE,\n",
    "        \"EMBED_DIM\": EMBED_DIM,\n",
    "        \"LSTM_LAYERS\": LSTM_LAYERS,\n",
    "        \"LSTM_H_DIM\": LSTM_H_DIM,\n",
    "        \"RNET_DROPOUT\": RNET_DROPOUT,\n",
    "        \"ENV_GAMMA\": ENV_GAMMA,\n",
    "        \"PGN_LR\": PGN_LR,\n",
    "        \"RNET_LR\": RNET_LR,\n",
    "        \"SRM_LR\": SRM_LR,\n",
    "        \"PGN_CLIP_GRAD\": PGN_CLIP_GRAD,\n",
    "        \"ENTROPY_BETA\": ENTROPY_BETA,\n",
    "        \"PRETRAIN_SRM_RNET_EPOCHS\": PRETRAIN_SRM_RNET_EPOCHS,\n",
    "        \"PRETRAIN_PGN_EPOCHS\": PRETRAIN_PGN_EPOCHS,\n",
    "        \"EPISODES_BATCH\": EPISODES_BATCH,\n",
    "        \"PRETRAIN_SRM_RNET_BATCH\": PRETRAIN_SRM_RNET_BATCH,\n",
    "        \"FEATURES\": FEATURES,\n",
    "        \"COMMENTS\": COMMENTS,\n",
    "    }\n",
    "\n",
    "\n",
    "def load_from_experiments(experiment: str) -> None:\n",
    "    global \\\n",
    "        RL_GAMMA, \\\n",
    "        REWARD_STEPS, \\\n",
    "        GLOVE_DIM, \\\n",
    "        TRAIN_SIZE, \\\n",
    "        TEST_SIZE, \\\n",
    "        EMBED_DIM, \\\n",
    "        LSTM_LAYERS, \\\n",
    "        LSTM_H_DIM, \\\n",
    "        RNET_DROPOUT, \\\n",
    "        ENV_GAMMA, \\\n",
    "        PGN_LR, \\\n",
    "        RNET_LR, \\\n",
    "        SRM_LR, \\\n",
    "        PGN_CLIP_GRAD, \\\n",
    "        ENTROPY_BETA, \\\n",
    "        PRETRAIN_SRM_RNET_EPOCHS, \\\n",
    "        PRETRAIN_PGN_EPOCHS, \\\n",
    "        EPISODES_BATCH, \\\n",
    "        PRETRAIN_SRM_RNET_BATCH, \\\n",
    "        FEATURES, \\\n",
    "        COMMENTS\n",
    "    with open(os.path.join(\".\", LOG_PATH_PREFIX, experiment, \"configs.json\"), \"r\") as f:\n",
    "        hyper_dict = json.load(f)\n",
    "    RL_GAMMA = hyper_dict[\"RL_GAMMA\"]\n",
    "    REWARD_STEPS = hyper_dict[\"REWARD_STEPS\"]\n",
    "    GLOVE_DIM = hyper_dict[\"GLOVE_DIM\"]\n",
    "    TRAIN_SIZE = hyper_dict[\"TRAIN_SIZE\"]\n",
    "    TEST_SIZE = hyper_dict[\"TEST_SIZE\"]\n",
    "    EMBED_DIM = hyper_dict[\"EMBED_DIM\"]\n",
    "    LSTM_LAYERS = hyper_dict[\"LSTM_LAYERS\"]\n",
    "    LSTM_H_DIM = hyper_dict[\"LSTM_H_DIM\"]\n",
    "    RNET_DROPOUT = hyper_dict[\"RNET_DROPOUT\"]\n",
    "    ENV_GAMMA = hyper_dict[\"ENV_GAMMA\"]\n",
    "    PGN_LR = hyper_dict[\"PGN_LR\"]\n",
    "    RNET_LR = hyper_dict[\"RNET_LR\"]\n",
    "    SRM_LR = hyper_dict[\"SRM_LR\"]\n",
    "    PGN_CLIP_GRAD = hyper_dict[\"PGN_CLIP_GRAD\"]\n",
    "    ENTROPY_BETA = hyper_dict[\"ENTROPY_BETA\"]\n",
    "    PRETRAIN_SRM_RNET_EPOCHS = hyper_dict[\"PRETRAIN_SRM_RNET_EPOCHS\"]\n",
    "    PRETRAIN_PGN_EPOCHS = hyper_dict[\"PRETRAIN_PGN_EPOCHS\"]\n",
    "    EPISODES_BATCH = hyper_dict[\"EPISODES_BATCH\"]\n",
    "    PRETRAIN_SRM_RNET_BATCH = hyper_dict[\"PRETRAIN_SRM_RNET_BATCH\"]\n",
    "    FEATURES = hyper_dict[\"FEATURES\"]\n",
    "    COMMENTS = hyper_dict[\"COMMENTS\"]\n",
    "    print(hyper_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d47aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDEFINED_COLORS = [\n",
    "    \"#ffa500\",\n",
    "    \"#c83cbc\",\n",
    "    \"#1c1c84\",\n",
    "    \"#ff0000\",\n",
    "    \"#08a4a7\",\n",
    "    \"#008000\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_plots(\n",
    "    data_dict: dict,\n",
    "    plots: list[tuple[dict, dict]],\n",
    "    title: str = \"\",\n",
    "    ylim=None,\n",
    "    row_plots: int = 1,\n",
    "    plot_width: float = 8,\n",
    "    plot_height: float = 4,\n",
    "    use_rainbow: bool = False,\n",
    "    use_common_legend: bool = False,\n",
    "    adjust: bool = False,\n",
    "):\n",
    "    num_plots = len(plots)\n",
    "    num_entities = max([len(x[1]) for x in plots]) + 1\n",
    "    if use_rainbow:\n",
    "        num_colors = num_entities\n",
    "        cm = plt.get_cmap(\"gist_rainbow\")\n",
    "        colors = [cm(1.0 * i / num_colors) for i in range(num_colors)]\n",
    "    else:\n",
    "        colors = PREDEFINED_COLORS\n",
    "\n",
    "    style_cycler = cycler(linestyle=[\"-\", \"--\", \":\", \"-.\"]) * cycler(color=colors)\n",
    "    column_plots = math.ceil(num_plots / row_plots)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        column_plots,\n",
    "        row_plots,\n",
    "        figsize=(plot_width * row_plots, plot_height * column_plots),\n",
    "    )\n",
    "\n",
    "    if len(title) > 0:\n",
    "        fig.suptitle(title, fontsize=14, y=1)\n",
    "    axs_list = [axs] if column_plots * row_plots == 1 else list(axs.flat)\n",
    "\n",
    "    for ax in axs_list:\n",
    "        ax.grid()\n",
    "        ax.set_prop_cycle(style_cycler)\n",
    "        if ylim is not None:\n",
    "            ax.set_ylim(top=ylim)\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    for ax, (p1, p2) in zip(axs_list, plots):\n",
    "        ax.set_visible(True)\n",
    "\n",
    "        ax.set_title(f\"{p2['axis_name']} over {p1['axis_name']}\")\n",
    "        ax.set(xlabel=p1[\"axis_label\"], ylabel=p2[\"axis_label\"])\n",
    "\n",
    "        if p1.get(\"log\", False):\n",
    "            ax.set_xscale(\"log\")\n",
    "        if p2.get(\"log\", False):\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        x_values = data_dict[p1.get(\"ref\", None) or p1[\"axis_name\"]]\n",
    "\n",
    "        p2vs = p2.get(\"values\", [])\n",
    "        if len(p2vs) == 0:\n",
    "            y_values = data_dict[p2.get(\"ref\", None) or p2[\"axis_name\"]]\n",
    "            ax.plot(x_values, y_values, label=p2[\"axis_name\"])\n",
    "            ax.scatter(x_values[-1], y_values[-1], s=15)\n",
    "            continue\n",
    "\n",
    "        for p2v in p2vs:\n",
    "            y_values = data_dict[p2v.get(\"ref\", None) or p2v[\"name\"]]\n",
    "\n",
    "            try:\n",
    "                iter(y_values)\n",
    "                ax.plot(x_values, y_values, label=p2v[\"name\"])\n",
    "                ax.scatter(x_values[-1], y_values[-1], s=15)\n",
    "            except TypeError:\n",
    "                ax.plot(x_values, [y_values] * len(x_values), label=p2v[\"name\"])\n",
    "\n",
    "    if use_common_legend:\n",
    "        lines_labels = [axs_list[0].get_legend_handles_labels()]\n",
    "        lines, labels = [sum(x, []) for x in zip(*lines_labels)]\n",
    "        fig.legend(\n",
    "            lines,\n",
    "            labels,\n",
    "            scatterpoints=1,\n",
    "            markerscale=3,\n",
    "            loc=\"outside lower center\",\n",
    "            ncol=min(6, num_entities),\n",
    "            bbox_to_anchor=(0.5, -0.05),\n",
    "        )\n",
    "    else:\n",
    "        if num_entities > 1:\n",
    "            for ax, _ in zip(axs_list, plots):\n",
    "                ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if adjust:\n",
    "        plt.subplots_adjust(\n",
    "            top=1 - 0.1 / (num_plots**0.5), bottom=0.12 / (num_plots**2), hspace=0.15\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def draw_plots(\n",
    "    data_dict: dict,\n",
    "    plots: list[tuple[dict, dict]],\n",
    "    title: str = \"\",\n",
    "    ylim=None,\n",
    "    row_plots: int = 1,\n",
    "    plot_width: float = 8,\n",
    "    plot_height: float = 4,\n",
    "    use_rainbow: bool = False,\n",
    "    use_common_legend: bool = False,\n",
    "    adjust: bool = False,\n",
    "):\n",
    "    get_plots(\n",
    "        data_dict,\n",
    "        plots,\n",
    "        title,\n",
    "        ylim,\n",
    "        row_plots,\n",
    "        plot_width,\n",
    "        plot_height,\n",
    "        use_rainbow,\n",
    "        use_common_legend,\n",
    "        adjust,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6febb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH_PREFIX = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db33aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoggerEntity = Literal[\"data\"] | Literal[\"model\"] | Literal[\"best\"] | Literal[\"plots\"]\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    _plot_epoch_axis = {\"axis_name\": \"Epoch\", \"axis_label\": \"Epoch\"}\n",
    "    _plot_time_axis = {\"axis_name\": \"Time\", \"axis_label\": \"Running time, seconds\"}\n",
    "    log_plots = [\n",
    "        (\n",
    "            _plot_epoch_axis,\n",
    "            {\"axis_name\": \"Mean PGN Loss\", \"axis_label\": \"Loss\"},\n",
    "        ),\n",
    "        (\n",
    "            {**_plot_epoch_axis, \"ref\": \"Eval Epoch\"},\n",
    "            {\"axis_name\": \"Mean Test Loss\", \"axis_label\": \"Loss\"},\n",
    "        ),\n",
    "        (\n",
    "            _plot_epoch_axis,\n",
    "            {\n",
    "                \"axis_name\": \"Mean Reward\",\n",
    "                \"axis_label\": \"Reward\",\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            _plot_epoch_axis,\n",
    "            {\n",
    "                \"axis_name\": \"Deletions ratio\",\n",
    "                \"axis_label\": \"deleted / total\",\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            {**_plot_epoch_axis, \"ref\": \"Eval Epoch\"},\n",
    "            {\"axis_name\": \"Test Deletions ratio\", \"axis_label\": \"deleted / total\"},\n",
    "        ),\n",
    "        (\n",
    "            _plot_epoch_axis,\n",
    "            {\n",
    "                \"axis_name\": \"Entropy\",\n",
    "                \"axis_label\": \"Entropy\",\n",
    "                \"values\": [{\"name\": \"Entropy\"}, {\"name\": \"Uniform entropy\"}],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            _plot_epoch_axis,\n",
    "            {\n",
    "                \"axis_name\": \"PGN Loss Structure\",\n",
    "                \"axis_label\": \"Loss\",\n",
    "                \"values\": [\n",
    "                    {\"name\": \"PGN Loss\", \"ref\": \"Mean PGN Loss\"},\n",
    "                    {\"name\": \"Policy Loss\", \"ref\": \"Mean PGN Policy Loss\"},\n",
    "                    {\"name\": \"Value Loss\", \"ref\": \"Mean PGN Value Loss\"},\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def _soft_mkdir(self, path: str) -> None:\n",
    "        with contextlib.suppress(Exception):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    def _soft_rmdir(self, path: str) -> None:\n",
    "        with contextlib.suppress(Exception):\n",
    "            shutil.rmtree(path)\n",
    "\n",
    "    def _get_max_index(self, path: str) -> int:\n",
    "        max_index = 0\n",
    "        for file in os.listdir(path):\n",
    "            with contextlib.suppress(ValueError):\n",
    "                max_index = max(max_index, int(os.path.splitext(file)[0]))\n",
    "        return max_index\n",
    "\n",
    "    def _remove_old(self):\n",
    "        if self.keep_last == -1:\n",
    "            return\n",
    "        if self.idx % self.keep_last != 0:\n",
    "            return\n",
    "        retain = [str(x) for x in range(self.idx, self.idx - self.keep_last, -1)] + [\n",
    "            \"0\",\n",
    "            \"best\",\n",
    "            \"configs.json\",\n",
    "        ]\n",
    "\n",
    "        abs_prefix = os.path.abspath(self.path)\n",
    "        for item in os.listdir(self.path):\n",
    "            if item not in retain:\n",
    "                self._soft_rmdir(os.path.join(abs_prefix, item))\n",
    "\n",
    "    def _save_json(self, path: str, data: dict) -> None:\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "    def _load_json(self, path: str) -> dict:\n",
    "        with open(path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def _save_configs(self) -> None:\n",
    "        self._save_json(os.path.join(self.path, \"configs.json\"), self.configs)\n",
    "\n",
    "    def _load_configs(self) -> dict:\n",
    "        return self._load_json(os.path.join(self.path, \"configs.json\"))\n",
    "\n",
    "    def _build_dirs(self) -> None:\n",
    "        self.dirs = {\n",
    "            \"models\": os.path.join(self.path, str(self.idx), \"models\"),\n",
    "            \"data\": os.path.join(self.path, str(self.idx), \"data\"),\n",
    "            \"plots\": os.path.join(self.path, str(self.idx), \"plots\"),\n",
    "            \"best\": os.path.join(self.path, \"best\"),\n",
    "        }\n",
    "\n",
    "        for dir_path in self.dirs.values():\n",
    "            self._soft_mkdir(dir_path)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        configs: dict,\n",
    "        path_prefix: str = LOG_PATH_PREFIX,\n",
    "        keep_last: int = 2,\n",
    "        force: bool = False,\n",
    "    ) -> None:\n",
    "        self.keep_last = keep_last\n",
    "        self.configs = configs\n",
    "        self.path = os.path.join(\".\", path_prefix, path)\n",
    "\n",
    "        if force:\n",
    "            self._soft_rmdir(os.path.abspath(self.path))\n",
    "\n",
    "        if os.path.exists(self.path):\n",
    "            self.new = False\n",
    "            self.load_state()\n",
    "        else:\n",
    "            self.new = True\n",
    "            self.init_state()\n",
    "\n",
    "    def init_state(self) -> None:\n",
    "        self.idx = 0\n",
    "        self._build_dirs()\n",
    "        self._save_configs()\n",
    "        self.save_best_dict({})\n",
    "\n",
    "    def load_state(self) -> None:\n",
    "        # Check compatibility\n",
    "        existed_configs = self._load_configs()\n",
    "        new_comments = self.configs.get(\"COMMENTS\")\n",
    "        del existed_configs[\"COMMENTS\"]\n",
    "        del self.configs[\"COMMENTS\"]\n",
    "        if existed_configs != self.configs:\n",
    "            raise Exception(\"Configs are not the same!\")\n",
    "        self.configs[\"COMMENTS\"] = new_comments\n",
    "\n",
    "        self.idx = self._get_max_index(self.path)\n",
    "        self._build_dirs()\n",
    "\n",
    "    def update_idx(self, inc_value: int):\n",
    "        self.new = False\n",
    "        self.idx += inc_value\n",
    "        self._build_dirs()\n",
    "        self._remove_old()\n",
    "\n",
    "    def load(self, name: str, entity: str, *data):\n",
    "        if entity == \"model\":\n",
    "            checkpoint = torch.load(os.path.join(self.dirs[\"models\"], name))\n",
    "            model, optimizer = data\n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            return None\n",
    "\n",
    "        if entity == \"data\":\n",
    "            return self._load_json(os.path.join(self.dirs[\"data\"], f\"{name}.json\"))\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save(self, name: str, entity: LoggerEntity, data, save_subplots: bool = False):\n",
    "        if entity == \"model\":\n",
    "            model, optimizer = data\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                },\n",
    "                os.path.join(self.dirs[\"models\"], name),\n",
    "            )\n",
    "            return\n",
    "        if entity == \"data\":\n",
    "            self._save_json(os.path.join(self.dirs[\"data\"], f\"{name}.json\"), data)\n",
    "            return\n",
    "\n",
    "        if entity == \"plots\":\n",
    "            plots_data = data\n",
    "            if save_subplots:\n",
    "                for single_plot in [[sp] for sp in self.log_plots]:\n",
    "                    fig = get_plots(plots_data, single_plot, row_plots=1)\n",
    "                    plot_name = f\"{single_plot[0][1]['axis_name']} over {single_plot[0][0]['axis_name']}\".replace(\n",
    "                        \" \", \"_\"\n",
    "                    ).lower()\n",
    "                    fig.savefig(\n",
    "                        os.path.join(self.dirs[\"plots\"], f\"{name}{plot_name}.png\")\n",
    "                    )\n",
    "                    plt.close()\n",
    "                    plt.clf()\n",
    "\n",
    "            fig = get_plots(plots_data, self.log_plots, row_plots=2)\n",
    "            fig.savefig(os.path.join(self.dirs[\"plots\"], f\"{name}all.png\"))\n",
    "            plt.close()\n",
    "            plt.clf()\n",
    "            return\n",
    "        if entity == \"best\":\n",
    "            best_info_dict, best_dict = data\n",
    "            best_path = os.path.abspath(self.dirs[\"best\"])\n",
    "            new_bests = {x[1] for x in best_dict.values()}\n",
    "\n",
    "            old_bests = set()\n",
    "            for item in os.listdir(best_path):\n",
    "                with contextlib.suppress(BaseException):\n",
    "                    old_bests.add(int(item))\n",
    "\n",
    "            # delete old\n",
    "            to_delete = old_bests.difference(new_bests)\n",
    "            for epoch in to_delete:\n",
    "                self._soft_rmdir(os.path.join(best_path, str(epoch)))\n",
    "\n",
    "            # save new\n",
    "            for epoch, best_data in best_info_dict.items():\n",
    "                if epoch not in new_bests:\n",
    "                    continue\n",
    "                for model_name, (model_state, optimizer_state) in best_data[\n",
    "                    \"models\"\n",
    "                ].items():\n",
    "                    path_prefix = os.path.join(best_path, str(epoch), \"models\")\n",
    "                    self._soft_mkdir(path_prefix)\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            \"model_state_dict\": model_state,\n",
    "                            \"optimizer_state_dict\": optimizer_state,\n",
    "                        },\n",
    "                        os.path.join(path_prefix, model_name),\n",
    "                    )\n",
    "                for file_name, file_data in best_data[\"data\"].items():\n",
    "                    path_prefix = os.path.join(best_path, str(epoch), \"data\")\n",
    "                    self._soft_mkdir(path_prefix)\n",
    "                    self._save_json(\n",
    "                        os.path.join(path_prefix, f\"{file_name}.json\"), file_data\n",
    "                    )\n",
    "            return\n",
    "\n",
    "    def save_best_dict(self, best_dict: dict) -> None:\n",
    "        self._save_json(os.path.join(self.path, \"best.json\"), best_dict)\n",
    "\n",
    "    def load_best_dict(self) -> dict:\n",
    "        res_dict = {}\n",
    "        for k, v in self._load_json(os.path.join(self.path, \"best.json\")).items():\n",
    "            res_dict[float(k)] = v\n",
    "        return res_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def update_best_dict(\n",
    "        best_dict: dict, loss, deletions_ratio: float, epoch: int\n",
    "    ) -> tuple[dict, bool]:\n",
    "        check_ls = [\n",
    "            float(ls) for r, (ls, _) in best_dict.items() if float(r) >= deletions_ratio\n",
    "        ]\n",
    "\n",
    "        # check if we removed more and got less loss\n",
    "        if len(check_ls) > 0 and loss >= min(check_ls):\n",
    "            return best_dict, False\n",
    "\n",
    "        # remove when we deleted less and got bigger loss\n",
    "        to_delete = [\n",
    "            float(r)\n",
    "            for r, (ls, _) in best_dict.items()\n",
    "            if float(r) <= deletions_ratio and float(ls) >= loss\n",
    "        ]\n",
    "        for del_k in to_delete:\n",
    "            del best_dict[del_k]\n",
    "\n",
    "        best_dict[deletions_ratio] = [loss, epoch]\n",
    "        return best_dict, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d974217",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2CNet(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int = 128) -> None:\n",
    "        super(A2CNet, self).__init__()\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        body_out = self.body(x)\n",
    "        return self.policy(body_out), self.value(body_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e507191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def choose_action(self, action_logits):\n",
    "        return random.choices(range(len(action_logits)), F.softmax(action_logits, dim=0))[\n",
    "            0\n",
    "        ]\n",
    "\n",
    "    def choose_optimal_action(self, action_logits) -> int:\n",
    "        return int(np.argmax(F.softmax(action_logits, dim=0).cpu()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c3587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_qvals(\n",
    "    rewards: list[float], gamma: float = RL_GAMMA, reward_steps: int = REWARD_STEPS\n",
    ") -> np.ndarray:\n",
    "    rw_steps = reward_steps if reward_steps != 0 else len(rewards)\n",
    "\n",
    "    return np.array(\n",
    "        [\n",
    "            list(\n",
    "                accumulate(\n",
    "                    reversed(rewards[i : i + rw_steps]), lambda x, y: gamma * x + y\n",
    "                )\n",
    "            )[-1]\n",
    "            for i in range(len(rewards))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f948ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryBuffer:\n",
    "    \"\"\"\n",
    "    Buffer class to store the experience from a unique policy\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.discounted_rewards = []\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        states_trajectory: np.ndarray,\n",
    "        trajectory: np.ndarray,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Add trajectory values to the buffers and compute the advantage and reward to go\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        states_trajectory:  list that contains states\n",
    "        trajectory: list where each element is a list that contains: reward, action\n",
    "        tokens_info: (target_tokens, candidate_tokens, score)\n",
    "        \"\"\"\n",
    "        assert len(states_trajectory) == len(trajectory)\n",
    "\n",
    "        if len(states_trajectory) > 0:\n",
    "            self.states.extend(states_trajectory)\n",
    "            self.rewards.extend(trajectory[:, 0])\n",
    "            self.actions.extend(trajectory[:, 1])\n",
    "\n",
    "            self.discounted_rewards.extend(calculate_qvals(trajectory[:, 0]))\n",
    "\n",
    "    def get_batch(self):\n",
    "        return self.states, self.actions, self.discounted_rewards\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.states) == len(self.actions) == len(self.discounted_rewards)\n",
    "        return len(self.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6b2d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = Logger(EXPERIMENT_NAME, pack_hyperparameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4faa6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOGGER.new:\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0450e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = {\n",
    "    \"Mean Reward\": [],\n",
    "    \"Mean Episode Length\": [],\n",
    "    \"Mean PGN Loss\": [],\n",
    "    \"Mean PGN Policy Loss\": [],\n",
    "    \"Mean PGN Value Loss\": [],\n",
    "    \"Mean Test Loss\": [],\n",
    "    \"Entropy\": [],\n",
    "    \"Eval Epoch\": [],\n",
    "    \"Eval Time\": [],\n",
    "    \"Epoch\": [],\n",
    "    \"Time\": [],\n",
    "}\n",
    "\n",
    "statistics = {\n",
    "    \"Initial Target length\": [],\n",
    "    \"Initial Candidate length\": [],\n",
    "    \"Processed Target length\": [],\n",
    "    \"Processed Candidate length\": [],\n",
    "    \"Deletions\": [],\n",
    "    \"Deletions ratio\": [],\n",
    "    \"Test Deletions ratio\": [],\n",
    "    \"RNet reward\": [],\n",
    "    \"Deletions reward\": [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d535cf8a",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d81299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "ROOT_FOLDER = os.path.join(\".\", \"..\")\n",
    "if ROOT_FOLDER not in sys.path:\n",
    "    sys.path.insert(0, ROOT_FOLDER)\n",
    "\n",
    "\n",
    "from dataset import RegexDataset\n",
    "from environmentV2 import EnvironmentV2, EnvSettings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.disable(logging.WARNING)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f6fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a2d', [0, 1, 0], 1)\n",
      "('2bb', [1, 0, 0], 1)\n",
      "('a2d', [0, 1, 0], 1)\n",
      "('2bb', [1, 0, 0], 1)\n",
      "('2bb', [1, 0, 0], 1)\n",
      "('a2d', [0, 1, 0], 1)\n",
      "('2bb', [1, 0, 0], 1)\n",
      "('a2d', [0, 1, 0], 1)\n",
      "('a2d', [0, 1, 0], 1)\n",
      "('2bb', [1, 0, 0], 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = RegexDataset([\"a2d\", \"2bb\"], r\"\\d+\")\n",
    "data_iter = dataset.create_iterator()\n",
    "\n",
    "for i in range(10):\n",
    "    print(next(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "592f29fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = EnvironmentV2(RegexDataset([\"a45d\", \"45bb\"], r\"\\d+\"), settings=EnvSettings(max_steps=3))\n",
    "\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf94d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "\n",
    "pgn = A2CNet(\n",
    "    input_dim=env.state_space, output_dim=env.action_space\n",
    ").to(DEVICE)\n",
    "pgn_optimizer = optim.Adam(pgn.parameters(), lr=PGN_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b809e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_entropy(n_actions: int):\n",
    "    probs = np.array([1 / n_actions for _ in range(n_actions)])\n",
    "    return -np.sum(probs * np.log(probs))\n",
    "\n",
    "\n",
    "def moving_average(x, w=10):\n",
    "    w = min(w, max(1, len(x) // 10))\n",
    "    return scipy.signal.savgol_filter(x, w, min(3, w - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1adb517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32386d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    pgn: nn.Module,\n",
    "    agent: Agent,\n",
    "    env,\n",
    "):  # (losses, deleted ratio, deletion statistics)\n",
    "    pgn.eval()\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.tensor(state, dtype=torch.float32, device=DEVICE)\n",
    "                action_logits = pgn(state_tensor)[0]\n",
    "\n",
    "            action = agent.choose_optimal_action(action_logits)\n",
    "            state2, _, done = env.step(action)\n",
    "            state = copy(state2)\n",
    "\n",
    "            if done:\n",
    "                state = env.reset()\n",
    "                print(\"EVAL: \", env.get_regexp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff96d046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 100%|██████████| 10/10 [00:00<00:00, 85.46it/s, Mean reward=-0.549, Mean PGN Loss=-0.941, Entropy=2.39]\n",
      "Epoch #2: 100%|██████████| 10/10 [00:00<00:00, 1000.00it/s, Mean reward=-0.604, Mean PGN Loss=-0.807, Entropy=2.39]\n",
      "Epoch #3: 100%|██████████| 10/10 [00:00<00:00, 1000.17it/s, Mean reward=-0.511, Mean PGN Loss=-0.431, Entropy=2.38]\n",
      "Epoch #4: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=-0.33, Mean PGN Loss=0.8, Entropy=2.37]\n",
      "Epoch #5: 100%|██████████| 10/10 [00:00<00:00, 1171.63it/s, Mean reward=-0.257, Mean PGN Loss=1.25, Entropy=2.36]\n",
      "Epoch #6: 100%|██████████| 10/10 [00:00<00:00, 769.23it/s, Mean reward=-0.532, Mean PGN Loss=0.15, Entropy=2.34]\n",
      "Epoch #7: 100%|██████████| 10/10 [00:00<00:00, 476.17it/s, Mean reward=-0.312, Mean PGN Loss=1.32, Entropy=2.3]\n",
      "Epoch #8: 100%|██████████| 10/10 [00:00<00:00, 999.98it/s, Mean reward=-0.511, Mean PGN Loss=0.209, Entropy=2.25]\n",
      "Epoch #9: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=-0.216, Mean PGN Loss=1.44, Entropy=2.17]\n",
      "Epoch #10: 100%|██████████| 10/10 [00:00<00:00, 1000.07it/s, Mean reward=-0.494, Mean PGN Loss=0.105, Entropy=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 100%|██████████| 10/10 [00:00<00:00, 1249.72it/s, Mean reward=-0.456, Mean PGN Loss=-0.0189, Entropy=1.9]\n",
      "Epoch #12: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=0.357, Mean PGN Loss=3.51, Entropy=1.61]\n",
      "Epoch #13: 100%|██████████| 10/10 [00:00<00:00, 1428.53it/s, Mean reward=-0.439, Mean PGN Loss=-0.209, Entropy=1.43]\n",
      "Epoch #14: 100%|██████████| 10/10 [00:00<00:00, 1428.53it/s, Mean reward=-0.38, Mean PGN Loss=-0.241, Entropy=1.18]\n",
      "Epoch #15: 100%|██████████| 10/10 [00:00<00:00, 2000.05it/s, Mean reward=-0.0052, Mean PGN Loss=2.1, Entropy=1.02]\n",
      "Epoch #16: 100%|██████████| 10/10 [00:00<00:00, 1666.72it/s, Mean reward=-0.304, Mean PGN Loss=-0.101, Entropy=0.852]\n",
      "Epoch #17: 100%|██████████| 10/10 [00:00<00:00, 1666.59it/s, Mean reward=0.488, Mean PGN Loss=4.34, Entropy=0.734]\n",
      "Epoch #18: 100%|██████████| 10/10 [00:00<00:00, 2000.05it/s, Mean reward=-0.0052, Mean PGN Loss=1.74, Entropy=0.844]\n",
      "Epoch #19: 100%|██████████| 10/10 [00:00<00:00, 1666.66it/s, Mean reward=0.231, Mean PGN Loss=2.59, Entropy=0.895]\n",
      "Epoch #20: 100%|██████████| 10/10 [00:00<00:00, 1666.46it/s, Mean reward=1, Mean PGN Loss=4.91, Entropy=0.922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #21: 100%|██████████| 10/10 [00:00<00:00, 1666.85it/s, Mean reward=0.766, Mean PGN Loss=4.1, Entropy=1.09]\n",
      "Epoch #22: 100%|██████████| 10/10 [00:00<00:00, 1428.38it/s, Mean reward=0.45, Mean PGN Loss=1.93, Entropy=1.19]\n",
      "Epoch #23: 100%|██████████| 10/10 [00:00<00:00, 1428.63it/s, Mean reward=1.17, Mean PGN Loss=5.51, Entropy=1.21]\n",
      "Epoch #24: 100%|██████████| 10/10 [00:00<00:00, 1428.53it/s, Mean reward=0.542, Mean PGN Loss=2.85, Entropy=1.24]\n",
      "Epoch #25: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=0.611, Mean PGN Loss=1.15, Entropy=1.26]\n",
      "Epoch #26: 100%|██████████| 10/10 [00:00<00:00, 1428.82it/s, Mean reward=0.337, Mean PGN Loss=0.847, Entropy=1.16]\n",
      "Epoch #27: 100%|██████████| 10/10 [00:00<00:00, 1413.75it/s, Mean reward=0.176, Mean PGN Loss=0.792, Entropy=1.2]\n",
      "Epoch #28: 100%|██████████| 10/10 [00:00<00:00, 1667.25it/s, Mean reward=0.395, Mean PGN Loss=1.15, Entropy=1.12]\n",
      "Epoch #29: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=1.13, Mean PGN Loss=2.06, Entropy=1.02]\n",
      "Epoch #30: 100%|██████████| 10/10 [00:00<00:00, 1250.46it/s, Mean reward=0.261, Mean PGN Loss=0.436, Entropy=0.988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #31: 100%|██████████| 10/10 [00:00<00:00, 1666.26it/s, Mean reward=0.176, Mean PGN Loss=1.12, Entropy=0.953]\n",
      "Epoch #32: 100%|██████████| 10/10 [00:00<00:00, 1428.29it/s, Mean reward=0.1, Mean PGN Loss=0.758, Entropy=0.869]\n",
      "Epoch #33: 100%|██████████| 10/10 [00:00<00:00, 1250.43it/s, Mean reward=1.87, Mean PGN Loss=5.61, Entropy=0.824]\n",
      "Epoch #34: 100%|██████████| 10/10 [00:00<00:00, 1428.29it/s, Mean reward=0.91, Mean PGN Loss=1.34, Entropy=0.742]\n",
      "Epoch #35: 100%|██████████| 10/10 [00:00<00:00, 1428.43it/s, Mean reward=1.65, Mean PGN Loss=3.49, Entropy=0.702]\n",
      "Epoch #36: 100%|██████████| 10/10 [00:00<00:00, 1428.67it/s, Mean reward=1.5, Mean PGN Loss=2.13, Entropy=0.653]\n",
      "Epoch #37: 100%|██████████| 10/10 [00:00<00:00, 1666.99it/s, Mean reward=2.05, Mean PGN Loss=2.02, Entropy=0.553]\n",
      "Epoch #38: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=1.61, Mean PGN Loss=5.21, Entropy=0.581]\n",
      "Epoch #39: 100%|██████████| 10/10 [00:00<00:00, 1428.67it/s, Mean reward=1.79, Mean PGN Loss=1.8, Entropy=0.544]\n",
      "Epoch #40: 100%|██████████| 10/10 [00:00<00:00, 1428.87it/s, Mean reward=1.72, Mean PGN Loss=1.14, Entropy=0.427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #41: 100%|██████████| 10/10 [00:00<00:00, 1428.97it/s, Mean reward=2.31, Mean PGN Loss=1.38, Entropy=0.399]\n",
      "Epoch #42: 100%|██████████| 10/10 [00:00<00:00, 1666.85it/s, Mean reward=1.79, Mean PGN Loss=0.706, Entropy=0.365]\n",
      "Epoch #43: 100%|██████████| 10/10 [00:00<00:00, 1249.90it/s, Mean reward=2.05, Mean PGN Loss=0.621, Entropy=0.305]\n",
      "Epoch #44: 100%|██████████| 10/10 [00:00<00:00, 1664.14it/s, Mean reward=2.24, Mean PGN Loss=1.93, Entropy=0.305]\n",
      "Epoch #45: 100%|██████████| 10/10 [00:00<00:00, 1428.33it/s, Mean reward=2.01, Mean PGN Loss=0.552, Entropy=0.209]\n",
      "Epoch #46: 100%|██████████| 10/10 [00:00<00:00, 1428.24it/s, Mean reward=2.31, Mean PGN Loss=0.255, Entropy=0.192]\n",
      "Epoch #47: 100%|██████████| 10/10 [00:00<00:00, 1428.72it/s, Mean reward=2.31, Mean PGN Loss=0.214, Entropy=0.206]\n",
      "Epoch #48: 100%|██████████| 10/10 [00:00<00:00, 1428.14it/s, Mean reward=2.49, Mean PGN Loss=1.22, Entropy=0.242]\n",
      "Epoch #49: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=2.31, Mean PGN Loss=0.0503, Entropy=0.141]\n",
      "Epoch #50: 100%|██████████| 10/10 [00:00<00:00, 1428.63it/s, Mean reward=2.05, Mean PGN Loss=-0.325, Entropy=0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #51: 100%|██████████| 10/10 [00:00<00:00, 1428.43it/s, Mean reward=2.49, Mean PGN Loss=0.895, Entropy=0.181]\n",
      "Epoch #52: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=2.31, Mean PGN Loss=0.116, Entropy=0.117]\n",
      "Epoch #53: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=2.01, Mean PGN Loss=0.754, Entropy=0.109]\n",
      "Epoch #54: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=2.49, Mean PGN Loss=0.751, Entropy=0.211]\n",
      "Epoch #55: 100%|██████████| 10/10 [00:00<00:00, 1429.21it/s, Mean reward=2.49, Mean PGN Loss=0.812, Entropy=0.175]\n",
      "Epoch #56: 100%|██████████| 10/10 [00:00<00:00, 1248.60it/s, Mean reward=2.31, Mean PGN Loss=0.218, Entropy=0.126]\n",
      "Epoch #57: 100%|██████████| 10/10 [00:00<00:00, 1428.72it/s, Mean reward=2.31, Mean PGN Loss=0.128, Entropy=0.18]\n",
      "Epoch #58: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=2.49, Mean PGN Loss=0.755, Entropy=0.198]\n",
      "Epoch #59: 100%|██████████| 10/10 [00:00<00:00, 1428.67it/s, Mean reward=2.31, Mean PGN Loss=0.163, Entropy=0.163]\n",
      "Epoch #60: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=2.49, Mean PGN Loss=0.704, Entropy=0.229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #61: 100%|██████████| 10/10 [00:00<00:00, 1428.29it/s, Mean reward=2.31, Mean PGN Loss=0.0484, Entropy=0.251]\n",
      "Epoch #62: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=2.31, Mean PGN Loss=0.0636, Entropy=0.228]\n",
      "Epoch #63: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=2.49, Mean PGN Loss=0.639, Entropy=0.301]\n",
      "Epoch #64: 100%|██████████| 10/10 [00:00<00:00, 1428.38it/s, Mean reward=2.49, Mean PGN Loss=0.586, Entropy=0.428]\n",
      "Epoch #65: 100%|██████████| 10/10 [00:00<00:00, 1428.24it/s, Mean reward=2.38, Mean PGN Loss=1.89, Entropy=0.516]\n",
      "Epoch #66: 100%|██████████| 10/10 [00:00<00:00, 1428.72it/s, Mean reward=2.31, Mean PGN Loss=-0.0217, Entropy=0.373]\n",
      "Epoch #67: 100%|██████████| 10/10 [00:00<00:00, 1428.43it/s, Mean reward=2.79, Mean PGN Loss=1.76, Entropy=0.585]\n",
      "Epoch #68: 100%|██████████| 10/10 [00:00<00:00, 1428.19it/s, Mean reward=1.72, Mean PGN Loss=1.37, Entropy=0.517]\n",
      "Epoch #69: 100%|██████████| 10/10 [00:00<00:00, 1428.48it/s, Mean reward=2.01, Mean PGN Loss=0.78, Entropy=0.459]\n",
      "Epoch #70: 100%|██████████| 10/10 [00:00<00:00, 1111.52it/s, Mean reward=2.2, Mean PGN Loss=1.35, Entropy=0.475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #71: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=1.9, Mean PGN Loss=1.91, Entropy=0.495]\n",
      "Epoch #72: 100%|██████████| 10/10 [00:00<00:00, 1249.90it/s, Mean reward=2.31, Mean PGN Loss=0.0229, Entropy=0.258]\n",
      "Epoch #73: 100%|██████████| 10/10 [00:00<00:00, 1249.76it/s, Mean reward=2.68, Mean PGN Loss=1.47, Entropy=0.275]\n",
      "Epoch #74: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=2.38, Mean PGN Loss=1.87, Entropy=0.29]\n",
      "Epoch #75: 100%|██████████| 10/10 [00:00<00:00, 1428.87it/s, Mean reward=2.68, Mean PGN Loss=1.57, Entropy=0.219]\n",
      "Epoch #76: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=2.68, Mean PGN Loss=1.56, Entropy=0.209]\n",
      "Epoch #77: 100%|██████████| 10/10 [00:00<00:00, 1666.79it/s, Mean reward=2.31, Mean PGN Loss=0.0307, Entropy=0.167]\n",
      "Epoch #78: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=2.68, Mean PGN Loss=1.45, Entropy=0.237]\n",
      "Epoch #79: 100%|██████████| 10/10 [00:00<00:00, 1428.63it/s, Mean reward=2.31, Mean PGN Loss=0.0126, Entropy=0.181]\n",
      "Epoch #80: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=2.68, Mean PGN Loss=1.26, Entropy=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #81: 100%|██████████| 10/10 [00:00<00:00, 1428.72it/s, Mean reward=2.31, Mean PGN Loss=0.00432, Entropy=0.211]\n",
      "Epoch #82: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=2.49, Mean PGN Loss=0.568, Entropy=0.246]\n",
      "Epoch #83: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=2.31, Mean PGN Loss=0.0113, Entropy=0.248]\n",
      "Epoch #84: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=2.68, Mean PGN Loss=0.927, Entropy=0.298]\n",
      "Epoch #85: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=2.86, Mean PGN Loss=1.21, Entropy=0.333]\n",
      "Epoch #86: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=3.05, Mean PGN Loss=1.37, Entropy=0.369]\n",
      "Epoch #87: 100%|██████████| 10/10 [00:00<00:00, 1249.90it/s, Mean reward=2.68, Mean PGN Loss=0.57, Entropy=0.427]\n",
      "Epoch #88: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=2.09, Mean PGN Loss=2.61, Entropy=0.448]\n",
      "Epoch #89: 100%|██████████| 10/10 [00:00<00:00, 1110.19it/s, Mean reward=3.23, Mean PGN Loss=1.05, Entropy=0.44]\n",
      "Epoch #90: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=2.57, Mean PGN Loss=1.78, Entropy=0.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #91: 100%|██████████| 10/10 [00:00<00:00, 1050.49it/s, Mean reward=3.31, Mean PGN Loss=2.05, Entropy=0.477]\n",
      "Epoch #92: 100%|██████████| 10/10 [00:00<00:00, 999.83it/s, Mean reward=3.01, Mean PGN Loss=2.93, Entropy=0.483] \n",
      "Epoch #93: 100%|██████████| 10/10 [00:00<00:00, 1250.28it/s, Mean reward=2.27, Mean PGN Loss=2.85, Entropy=0.441]\n",
      "Epoch #94: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=2.75, Mean PGN Loss=1.63, Entropy=0.446]\n",
      "Epoch #95: 100%|██████████| 10/10 [00:00<00:00, 1110.78it/s, Mean reward=2.83, Mean PGN Loss=2.86, Entropy=0.458]\n",
      "Epoch #96: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=2.16, Mean PGN Loss=4.5, Entropy=0.455]\n",
      "Epoch #97: 100%|██████████| 10/10 [00:00<00:00, 1249.90it/s, Mean reward=2.27, Mean PGN Loss=2.61, Entropy=0.403]\n",
      "Epoch #98: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=3.42, Mean PGN Loss=1.12, Entropy=0.375]\n",
      "Epoch #99: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=2.86, Mean PGN Loss=0.786, Entropy=0.369]\n",
      "Epoch #100: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=2.68, Mean PGN Loss=0.575, Entropy=0.406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #101: 100%|██████████| 10/10 [00:00<00:00, 1428.48it/s, Mean reward=2.86, Mean PGN Loss=0.873, Entropy=0.431]\n",
      "Epoch #102: 100%|██████████| 10/10 [00:00<00:00, 1249.83it/s, Mean reward=2.49, Mean PGN Loss=0.289, Entropy=0.54]\n",
      "Epoch #103: 100%|██████████| 10/10 [00:00<00:00, 555.51it/s, Mean reward=3.05, Mean PGN Loss=1.16, Entropy=0.492]\n",
      "Epoch #104: 100%|██████████| 10/10 [00:00<00:00, 1000.02it/s, Mean reward=3.23, Mean PGN Loss=1.32, Entropy=0.462]\n",
      "Epoch #105: 100%|██████████| 10/10 [00:00<00:00, 999.98it/s, Mean reward=3.23, Mean PGN Loss=1.17, Entropy=0.461] \n",
      "Epoch #106: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=3.42, Mean PGN Loss=1.15, Entropy=0.361]\n",
      "Epoch #107: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=3.12, Mean PGN Loss=1.25, Entropy=0.308]\n",
      "Epoch #108: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=3.31, Mean PGN Loss=1.9, Entropy=0.273]\n",
      "Epoch #109: 100%|██████████| 10/10 [00:00<00:00, 1111.46it/s, Mean reward=3.79, Mean PGN Loss=0.871, Entropy=0.252]\n",
      "Epoch #110: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=3.68, Mean PGN Loss=1.96, Entropy=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #111: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=3.2, Mean PGN Loss=2.8, Entropy=0.246]\n",
      "Epoch #112: 100%|██████████| 10/10 [00:00<00:00, 999.81it/s, Mean reward=4.16, Mean PGN Loss=0.646, Entropy=0.184] \n",
      "Epoch #113: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=3.68, Mean PGN Loss=1.62, Entropy=0.187]\n",
      "Epoch #114: 100%|██████████| 10/10 [00:00<00:00, 1111.02it/s, Mean reward=3.98, Mean PGN Loss=0.317, Entropy=0.156]\n",
      "Epoch #115: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=0.313, Entropy=0.143]\n",
      "Epoch #116: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=3.5, Mean PGN Loss=1.28, Entropy=0.178]\n",
      "Epoch #117: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=3.79, Mean PGN Loss=0.155, Entropy=0.208]\n",
      "Epoch #118: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=3.2, Mean PGN Loss=3.72, Entropy=0.225]\n",
      "Epoch #119: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=0.17, Entropy=0.181]\n",
      "Epoch #120: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.149, Entropy=0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #121: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=3.5, Mean PGN Loss=1.81, Entropy=0.202]\n",
      "Epoch #122: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=3.2, Mean PGN Loss=3.6, Entropy=0.139]\n",
      "Epoch #123: 100%|██████████| 10/10 [00:00<00:00, 1110.99it/s, Mean reward=4.16, Mean PGN Loss=0.103, Entropy=0.0868]\n",
      "Epoch #124: 100%|██████████| 10/10 [00:00<00:00, 1000.26it/s, Mean reward=4.16, Mean PGN Loss=0.107, Entropy=0.0662]\n",
      "Epoch #125: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=0.114, Entropy=0.0591]\n",
      "Epoch #126: 100%|██████████| 10/10 [00:00<00:00, 454.44it/s, Mean reward=4.16, Mean PGN Loss=0.121, Entropy=0.0584]\n",
      "Epoch #127: 100%|██████████| 10/10 [00:00<00:00, 625.15it/s, Mean reward=3.68, Mean PGN Loss=1.19, Entropy=0.0762]\n",
      "Epoch #128: 100%|██████████| 10/10 [00:00<00:00, 769.12it/s, Mean reward=4.16, Mean PGN Loss=0.132, Entropy=0.0699]\n",
      "Epoch #129: 100%|██████████| 10/10 [00:00<00:00, 909.04it/s, Mean reward=3.98, Mean PGN Loss=0.0905, Entropy=0.0841]\n",
      "Epoch #130: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=3.79, Mean PGN Loss=0.0728, Entropy=0.0971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #131: 100%|██████████| 10/10 [00:00<00:00, 1000.48it/s, Mean reward=3.98, Mean PGN Loss=0.0969, Entropy=0.095]\n",
      "Epoch #132: 100%|██████████| 10/10 [00:00<00:00, 909.02it/s, Mean reward=3.98, Mean PGN Loss=0.0834, Entropy=0.0916]\n",
      "Epoch #133: 100%|██████████| 10/10 [00:00<00:00, 1000.02it/s, Mean reward=3.98, Mean PGN Loss=0.0619, Entropy=0.0843]\n",
      "Epoch #134: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=3.98, Mean PGN Loss=0.0345, Entropy=0.0745]\n",
      "Epoch #135: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.0493, Entropy=0.0616]\n",
      "Epoch #136: 100%|██████████| 10/10 [00:00<00:00, 1091.75it/s, Mean reward=4.16, Mean PGN Loss=0.0328, Entropy=0.0538]\n",
      "Epoch #137: 100%|██████████| 10/10 [00:00<00:00, 1000.00it/s, Mean reward=4.16, Mean PGN Loss=0.0198, Entropy=0.0479]\n",
      "Epoch #138: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=0.0116, Entropy=0.0436]\n",
      "Epoch #139: 100%|██████████| 10/10 [00:00<00:00, 1250.43it/s, Mean reward=3.98, Mean PGN Loss=-0.054, Entropy=0.0417]\n",
      "Epoch #140: 100%|██████████| 10/10 [00:00<00:00, 999.98it/s, Mean reward=4.16, Mean PGN Loss=0.00936, Entropy=0.0351] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #141: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.0123, Entropy=0.0313]\n",
      "Epoch #142: 100%|██████████| 10/10 [00:00<00:00, 909.33it/s, Mean reward=4.16, Mean PGN Loss=0.016, Entropy=0.0283] \n",
      "Epoch #143: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=3.98, Mean PGN Loss=-0.0692, Entropy=0.0293]\n",
      "Epoch #144: 100%|██████████| 10/10 [00:00<00:00, 1000.02it/s, Mean reward=4.16, Mean PGN Loss=0.0198, Entropy=0.0231]\n",
      "Epoch #145: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.0189, Entropy=0.0211]\n",
      "Epoch #146: 100%|██████████| 10/10 [00:00<00:00, 1000.05it/s, Mean reward=4.16, Mean PGN Loss=0.0169, Entropy=0.0198]\n",
      "Epoch #147: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=3.68, Mean PGN Loss=1.32, Entropy=0.0399]\n",
      "Epoch #148: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.00888, Entropy=0.0179]\n",
      "Epoch #149: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=0.0071, Entropy=0.0176]\n",
      "Epoch #150: 100%|██████████| 10/10 [00:00<00:00, 1000.17it/s, Mean reward=4.16, Mean PGN Loss=0.00826, Entropy=0.0178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #151: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=0.0112, Entropy=0.0184]\n",
      "Epoch #152: 100%|██████████| 10/10 [00:00<00:00, 999.64it/s, Mean reward=4.16, Mean PGN Loss=0.0148, Entropy=0.0195]\n",
      "Epoch #153: 100%|██████████| 10/10 [00:00<00:00, 1000.19it/s, Mean reward=3.68, Mean PGN Loss=0.986, Entropy=0.0207]\n",
      "Epoch #154: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=0.0274, Entropy=0.0226]\n",
      "Epoch #155: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=0.0358, Entropy=0.0251]\n",
      "Epoch #156: 100%|██████████| 10/10 [00:00<00:00, 999.95it/s, Mean reward=4.16, Mean PGN Loss=0.0407, Entropy=0.028] \n",
      "Epoch #157: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.0414, Entropy=0.0312]\n",
      "Epoch #158: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=0.0379, Entropy=0.0346]\n",
      "Epoch #159: 100%|██████████| 10/10 [00:00<00:00, 999.93it/s, Mean reward=3.98, Mean PGN Loss=-0.0255, Entropy=0.0398] \n",
      "Epoch #160: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=4.16, Mean PGN Loss=0.0252, Entropy=0.0374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #161: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.0182, Entropy=0.0369]\n",
      "Epoch #162: 100%|██████████| 10/10 [00:00<00:00, 999.98it/s, Mean reward=4.16, Mean PGN Loss=0.0118, Entropy=0.0365]\n",
      "Epoch #163: 100%|██████████| 10/10 [00:00<00:00, 1111.34it/s, Mean reward=4.16, Mean PGN Loss=0.00706, Entropy=0.0364]\n",
      "Epoch #164: 100%|██████████| 10/10 [00:00<00:00, 1111.46it/s, Mean reward=3.98, Mean PGN Loss=-0.0609, Entropy=0.0367]\n",
      "Epoch #165: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=0.00393, Entropy=0.0327]\n",
      "Epoch #166: 100%|██████████| 10/10 [00:00<00:00, 1111.40it/s, Mean reward=4.16, Mean PGN Loss=0.00445, Entropy=0.0302]\n",
      "Epoch #167: 100%|██████████| 10/10 [00:00<00:00, 1110.99it/s, Mean reward=4.16, Mean PGN Loss=0.00556, Entropy=0.0284]\n",
      "Epoch #168: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.00678, Entropy=0.0271]\n",
      "Epoch #169: 100%|██████████| 10/10 [00:00<00:00, 1249.79it/s, Mean reward=4.16, Mean PGN Loss=0.0077, Entropy=0.0262]\n",
      "Epoch #170: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.00805, Entropy=0.0256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #171: 100%|██████████| 10/10 [00:00<00:00, 1110.84it/s, Mean reward=4.16, Mean PGN Loss=0.00776, Entropy=0.0253]\n",
      "Epoch #172: 100%|██████████| 10/10 [00:00<00:00, 1000.12it/s, Mean reward=4.16, Mean PGN Loss=0.00694, Entropy=0.0252]\n",
      "Epoch #173: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=0.00581, Entropy=0.0252]\n",
      "Epoch #174: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.00462, Entropy=0.0253]\n",
      "Epoch #175: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.00359, Entropy=0.0254]\n",
      "Epoch #176: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=0.00289, Entropy=0.0255]\n",
      "Epoch #177: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.00255, Entropy=0.0257]\n",
      "Epoch #178: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.00253, Entropy=0.0259]\n",
      "Epoch #179: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=0.00273, Entropy=0.026]\n",
      "Epoch #180: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=4.16, Mean PGN Loss=0.003, Entropy=0.0262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #181: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=3.79, Mean PGN Loss=-0.118, Entropy=0.0281]\n",
      "Epoch #182: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.00437, Entropy=0.0207]\n",
      "Epoch #183: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=3.98, Mean PGN Loss=-0.173, Entropy=0.0168]\n",
      "Epoch #184: 100%|██████████| 10/10 [00:00<00:00, 1110.99it/s, Mean reward=3.98, Mean PGN Loss=-0.121, Entropy=0.0149]\n",
      "Epoch #185: 100%|██████████| 10/10 [00:00<00:00, 1000.17it/s, Mean reward=4.16, Mean PGN Loss=0.00883, Entropy=0.012]\n",
      "Epoch #186: 100%|██████████| 10/10 [00:00<00:00, 1111.40it/s, Mean reward=4.16, Mean PGN Loss=0.0098, Entropy=0.0108]\n",
      "Epoch #187: 100%|██████████| 10/10 [00:00<00:00, 909.18it/s, Mean reward=4.16, Mean PGN Loss=0.00969, Entropy=0.0103] \n",
      "Epoch #188: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.00861, Entropy=0.0101]\n",
      "Epoch #189: 100%|██████████| 10/10 [00:00<00:00, 1111.34it/s, Mean reward=4.16, Mean PGN Loss=0.00691, Entropy=0.0103]\n",
      "Epoch #190: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.00501, Entropy=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #191: 100%|██████████| 10/10 [00:00<00:00, 1250.31it/s, Mean reward=4.16, Mean PGN Loss=0.00333, Entropy=0.011]\n",
      "Epoch #192: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=4.16, Mean PGN Loss=0.00215, Entropy=0.0116]\n",
      "Epoch #193: 100%|██████████| 10/10 [00:00<00:00, 1111.49it/s, Mean reward=4.16, Mean PGN Loss=0.00159, Entropy=0.0121]\n",
      "Epoch #194: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=0.00159, Entropy=0.0128]\n",
      "Epoch #195: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.00197, Entropy=0.0134]\n",
      "Epoch #196: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=0.0025, Entropy=0.0141]\n",
      "Epoch #197: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=0.00294, Entropy=0.0148]\n",
      "Epoch #198: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=0.00313, Entropy=0.0154]\n",
      "Epoch #199: 100%|██████████| 10/10 [00:00<00:00, 1249.76it/s, Mean reward=4.16, Mean PGN Loss=0.00302, Entropy=0.0161]\n",
      "Epoch #200: 100%|██████████| 10/10 [00:00<00:00, 1249.76it/s, Mean reward=4.16, Mean PGN Loss=0.00263, Entropy=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #201: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.00208, Entropy=0.0173]\n",
      "Epoch #202: 100%|██████████| 10/10 [00:00<00:00, 999.88it/s, Mean reward=4.16, Mean PGN Loss=0.00148, Entropy=0.0179] \n",
      "Epoch #203: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.000975, Entropy=0.0184]\n",
      "Epoch #204: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=0.000638, Entropy=0.0189]\n",
      "Epoch #205: 100%|██████████| 10/10 [00:00<00:00, 1250.20it/s, Mean reward=4.16, Mean PGN Loss=0.000501, Entropy=0.0194]\n",
      "Epoch #206: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.000539, Entropy=0.0198]\n",
      "Epoch #207: 100%|██████████| 10/10 [00:00<00:00, 1249.87it/s, Mean reward=4.16, Mean PGN Loss=0.000689, Entropy=0.0202]\n",
      "Epoch #208: 100%|██████████| 10/10 [00:00<00:00, 1428.97it/s, Mean reward=4.16, Mean PGN Loss=0.000874, Entropy=0.0206]\n",
      "Epoch #209: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.00102, Entropy=0.0209]\n",
      "Epoch #210: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=3.68, Mean PGN Loss=1.3, Entropy=0.0404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #211: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=0.00304, Entropy=0.0144]\n",
      "Epoch #212: 100%|██████████| 10/10 [00:00<00:00, 1110.75it/s, Mean reward=4.16, Mean PGN Loss=0.00539, Entropy=0.0109]\n",
      "Epoch #213: 100%|██████████| 10/10 [00:00<00:00, 1111.49it/s, Mean reward=4.16, Mean PGN Loss=0.00735, Entropy=0.00941]\n",
      "Epoch #214: 100%|██████████| 10/10 [00:00<00:00, 1249.64it/s, Mean reward=4.16, Mean PGN Loss=0.00836, Entropy=0.0092]\n",
      "Epoch #215: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=4.16, Mean PGN Loss=0.00822, Entropy=0.00981]\n",
      "Epoch #216: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=4.16, Mean PGN Loss=0.00706, Entropy=0.011]\n",
      "Epoch #217: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=3.68, Mean PGN Loss=1.25, Entropy=0.024]\n",
      "Epoch #218: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=4.16, Mean PGN Loss=0.0083, Entropy=0.0126]\n",
      "Epoch #219: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=0.0104, Entropy=0.0129]\n",
      "Epoch #220: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=0.011, Entropy=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #221: 100%|██████████| 10/10 [00:00<00:00, 1111.40it/s, Mean reward=4.16, Mean PGN Loss=0.0101, Entropy=0.0141]\n",
      "Epoch #222: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.00816, Entropy=0.015]\n",
      "Epoch #223: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=0.00569, Entropy=0.016]\n",
      "Epoch #224: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=0.00333, Entropy=0.0172]\n",
      "Epoch #225: 100%|██████████| 10/10 [00:00<00:00, 1110.90it/s, Mean reward=4.16, Mean PGN Loss=0.00158, Entropy=0.0185]\n",
      "Epoch #226: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.00068, Entropy=0.0198]\n",
      "Epoch #227: 100%|██████████| 10/10 [00:00<00:00, 1111.34it/s, Mean reward=4.16, Mean PGN Loss=0.000627, Entropy=0.0211]\n",
      "Epoch #228: 100%|██████████| 10/10 [00:00<00:00, 1250.31it/s, Mean reward=4.16, Mean PGN Loss=0.00119, Entropy=0.0224]\n",
      "Epoch #229: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.00203, Entropy=0.0236]\n",
      "Epoch #230: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=0.0028, Entropy=0.0247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #231: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.00322, Entropy=0.0256]\n",
      "Epoch #232: 100%|██████████| 10/10 [00:00<00:00, 1000.10it/s, Mean reward=3.68, Mean PGN Loss=1.65, Entropy=0.0265]\n",
      "Epoch #233: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.000521, Entropy=0.012]\n",
      "Epoch #234: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=0.00141, Entropy=0.00679]\n",
      "Epoch #235: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.00476, Entropy=0.00483]\n",
      "Epoch #236: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.00895, Entropy=0.00406]\n",
      "Epoch #237: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=0.0125, Entropy=0.00376]\n",
      "Epoch #238: 100%|██████████| 10/10 [00:00<00:00, 1110.93it/s, Mean reward=4.16, Mean PGN Loss=0.0142, Entropy=0.00366]\n",
      "Epoch #239: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=0.0139, Entropy=0.00366]\n",
      "Epoch #240: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=4.16, Mean PGN Loss=0.0118, Entropy=0.00372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #241: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=0.00856, Entropy=0.00381]\n",
      "Epoch #242: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=0.00514, Entropy=0.00392]\n",
      "Epoch #243: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=0.00235, Entropy=0.00404]\n",
      "Epoch #244: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.000693, Entropy=0.00417]\n",
      "Epoch #245: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.000299, Entropy=0.00431]\n",
      "Epoch #246: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=4.16, Mean PGN Loss=0.00094, Entropy=0.00446]\n",
      "Epoch #247: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=0.00215, Entropy=0.00461]\n",
      "Epoch #248: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.0034, Entropy=0.00477]\n",
      "Epoch #249: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.00424, Entropy=0.00492]\n",
      "Epoch #250: 100%|██████████| 10/10 [00:00<00:00, 1000.26it/s, Mean reward=4.16, Mean PGN Loss=0.00443, Entropy=0.00508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #251: 100%|██████████| 10/10 [00:00<00:00, 1110.93it/s, Mean reward=4.16, Mean PGN Loss=0.00398, Entropy=0.00525]\n",
      "Epoch #252: 100%|██████████| 10/10 [00:00<00:00, 909.04it/s, Mean reward=4.16, Mean PGN Loss=0.00307, Entropy=0.00541]\n",
      "Epoch #253: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=0.00198, Entropy=0.00557]\n",
      "Epoch #254: 100%|██████████| 10/10 [00:00<00:00, 1250.39it/s, Mean reward=4.16, Mean PGN Loss=0.00102, Entropy=0.00573]\n",
      "Epoch #255: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=4.16, Mean PGN Loss=0.000386, Entropy=0.0059]\n",
      "Epoch #256: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=4.16, Mean PGN Loss=0.000158, Entropy=0.00605]\n",
      "Epoch #257: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=4.16, Mean PGN Loss=0.000289, Entropy=0.0062]\n",
      "Epoch #258: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=0.000642, Entropy=0.00634]\n",
      "Epoch #259: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=0.00105, Entropy=0.00647]\n",
      "Epoch #260: 100%|██████████| 10/10 [00:00<00:00, 1110.75it/s, Mean reward=4.16, Mean PGN Loss=0.00135, Entropy=0.00658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #261: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=4.16, Mean PGN Loss=0.00146, Entropy=0.00668]\n",
      "Epoch #262: 100%|██████████| 10/10 [00:00<00:00, 1111.57it/s, Mean reward=4.16, Mean PGN Loss=0.00136, Entropy=0.00676]\n",
      "Epoch #263: 100%|██████████| 10/10 [00:00<00:00, 1000.31it/s, Mean reward=4.16, Mean PGN Loss=0.00109, Entropy=0.00683]\n",
      "Epoch #264: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=4.16, Mean PGN Loss=0.000747, Entropy=0.00689]\n",
      "Epoch #265: 100%|██████████| 10/10 [00:00<00:00, 434.72it/s, Mean reward=4.16, Mean PGN Loss=0.000421, Entropy=0.00694]\n",
      "Epoch #266: 100%|██████████| 10/10 [00:00<00:00, 769.44it/s, Mean reward=4.16, Mean PGN Loss=0.000185, Entropy=0.00699]\n",
      "Epoch #267: 100%|██████████| 10/10 [00:00<00:00, 714.19it/s, Mean reward=4.16, Mean PGN Loss=7.58e-5, Entropy=0.00702]\n",
      "Epoch #268: 100%|██████████| 10/10 [00:00<00:00, 1110.87it/s, Mean reward=4.16, Mean PGN Loss=8.76e-5, Entropy=0.00706]\n",
      "Epoch #269: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.000181, Entropy=0.00709]\n",
      "Epoch #270: 100%|██████████| 10/10 [00:00<00:00, 999.76it/s, Mean reward=4.16, Mean PGN Loss=0.000303, Entropy=0.00712] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #271: 100%|██████████| 10/10 [00:00<00:00, 1110.87it/s, Mean reward=4.16, Mean PGN Loss=0.000401, Entropy=0.00715]\n",
      "Epoch #272: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.000442, Entropy=0.00718]\n",
      "Epoch #273: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.000416, Entropy=0.00721]\n",
      "Epoch #274: 100%|██████████| 10/10 [00:00<00:00, 1110.60it/s, Mean reward=4.16, Mean PGN Loss=0.000336, Entropy=0.00724]\n",
      "Epoch #275: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=0.000231, Entropy=0.00728]\n",
      "Epoch #276: 100%|██████████| 10/10 [00:00<00:00, 1111.02it/s, Mean reward=4.16, Mean PGN Loss=0.00013, Entropy=0.00731]\n",
      "Epoch #277: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=5.79e-5, Entropy=0.00734]\n",
      "Epoch #278: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=4.16, Mean PGN Loss=2.74e-5, Entropy=0.00737]\n",
      "Epoch #279: 100%|██████████| 10/10 [00:00<00:00, 1250.31it/s, Mean reward=4.16, Mean PGN Loss=3.58e-5, Entropy=0.0074]\n",
      "Epoch #280: 100%|██████████| 10/10 [00:00<00:00, 1110.93it/s, Mean reward=4.16, Mean PGN Loss=7.01e-5, Entropy=0.00742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #281: 100%|██████████| 10/10 [00:00<00:00, 1110.99it/s, Mean reward=4.16, Mean PGN Loss=0.000112, Entropy=0.00744]\n",
      "Epoch #282: 100%|██████████| 10/10 [00:00<00:00, 1110.99it/s, Mean reward=4.16, Mean PGN Loss=0.000145, Entropy=0.00745]\n",
      "Epoch #283: 100%|██████████| 10/10 [00:00<00:00, 1331.48it/s, Mean reward=4.16, Mean PGN Loss=0.000158, Entropy=0.00747]\n",
      "Epoch #284: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=0.000148, Entropy=0.00748]\n",
      "Epoch #285: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.000119, Entropy=0.00748]\n",
      "Epoch #286: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=3.68, Mean PGN Loss=0.943, Entropy=0.00936]\n",
      "Epoch #287: 100%|██████████| 10/10 [00:00<00:00, 1249.90it/s, Mean reward=4.16, Mean PGN Loss=0.00165, Entropy=0.00893]\n",
      "Epoch #288: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=0.00439, Entropy=0.0111]\n",
      "Epoch #289: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=3.98, Mean PGN Loss=-0.123, Entropy=0.0144]\n",
      "Epoch #290: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=4.16, Mean PGN Loss=0.0103, Entropy=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #291: 100%|██████████| 10/10 [00:00<00:00, 1000.12it/s, Mean reward=4.16, Mean PGN Loss=0.0119, Entropy=0.0188]\n",
      "Epoch #292: 100%|██████████| 10/10 [00:00<00:00, 1000.00it/s, Mean reward=4.16, Mean PGN Loss=0.0116, Entropy=0.0229]\n",
      "Epoch #293: 100%|██████████| 10/10 [00:00<00:00, 1000.26it/s, Mean reward=4.16, Mean PGN Loss=0.00977, Entropy=0.0283]\n",
      "Epoch #294: 100%|██████████| 10/10 [00:00<00:00, 1249.90it/s, Mean reward=4.16, Mean PGN Loss=0.00703, Entropy=0.0347]\n",
      "Epoch #295: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=0.00424, Entropy=0.0422]\n",
      "Epoch #296: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=0.00209, Entropy=0.0505]\n",
      "Epoch #297: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=3.98, Mean PGN Loss=0.0189, Entropy=0.0615]\n",
      "Epoch #298: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=4.16, Mean PGN Loss=0.000842, Entropy=0.0546]\n",
      "Epoch #299: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.001, Entropy=0.0505]\n",
      "Epoch #300: 100%|██████████| 10/10 [00:00<00:00, 1250.20it/s, Mean reward=4.16, Mean PGN Loss=0.00127, Entropy=0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #301: 100%|██████████| 10/10 [00:00<00:00, 1110.90it/s, Mean reward=4.16, Mean PGN Loss=0.00149, Entropy=0.0441]\n",
      "Epoch #302: 100%|██████████| 10/10 [00:00<00:00, 1000.22it/s, Mean reward=4.16, Mean PGN Loss=0.00158, Entropy=0.0416]\n",
      "Epoch #303: 100%|██████████| 10/10 [00:00<00:00, 1250.46it/s, Mean reward=3.98, Mean PGN Loss=-0.0108, Entropy=0.0412]\n",
      "Epoch #304: 100%|██████████| 10/10 [00:00<00:00, 1110.93it/s, Mean reward=4.16, Mean PGN Loss=0.000992, Entropy=0.0289]\n",
      "Epoch #305: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=0.000763, Entropy=0.0217]\n",
      "Epoch #306: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.000817, Entropy=0.0169]\n",
      "Epoch #307: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=4.16, Mean PGN Loss=0.00107, Entropy=0.0136]\n",
      "Epoch #308: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=0.00137, Entropy=0.0112]\n",
      "Epoch #309: 100%|██████████| 10/10 [00:00<00:00, 1000.33it/s, Mean reward=4.16, Mean PGN Loss=0.00157, Entropy=0.00948]\n",
      "Epoch #310: 100%|██████████| 10/10 [00:00<00:00, 1110.96it/s, Mean reward=3.98, Mean PGN Loss=-0.15, Entropy=0.00944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #311: 100%|██████████| 10/10 [00:00<00:00, 1250.28it/s, Mean reward=4.16, Mean PGN Loss=0.00221, Entropy=0.00636]\n",
      "Epoch #312: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=4.16, Mean PGN Loss=0.00253, Entropy=0.00513]\n",
      "Epoch #313: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=0.00247, Entropy=0.00431]\n",
      "Epoch #314: 100%|██████████| 10/10 [00:00<00:00, 1250.20it/s, Mean reward=4.16, Mean PGN Loss=0.00207, Entropy=0.00373]\n",
      "Epoch #315: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.00148, Entropy=0.0033]\n",
      "Epoch #316: 100%|██████████| 10/10 [00:00<00:00, 1111.40it/s, Mean reward=4.16, Mean PGN Loss=0.000876, Entropy=0.00298]\n",
      "Epoch #317: 100%|██████████| 10/10 [00:00<00:00, 1110.87it/s, Mean reward=4.16, Mean PGN Loss=0.000421, Entropy=0.00275]\n",
      "Epoch #318: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=4.16, Mean PGN Loss=0.000194, Entropy=0.00257]\n",
      "Epoch #319: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.000195, Entropy=0.00243]\n",
      "Epoch #320: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=0.000354, Entropy=0.00233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #321: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=0.000567, Entropy=0.00224]\n",
      "Epoch #322: 100%|██████████| 10/10 [00:00<00:00, 1109.52it/s, Mean reward=4.16, Mean PGN Loss=0.000737, Entropy=0.00217]\n",
      "Epoch #323: 100%|██████████| 10/10 [00:00<00:00, 1250.28it/s, Mean reward=4.16, Mean PGN Loss=0.000799, Entropy=0.00212]\n",
      "Epoch #324: 100%|██████████| 10/10 [00:00<00:00, 1111.02it/s, Mean reward=4.16, Mean PGN Loss=0.000739, Entropy=0.00208]\n",
      "Epoch #325: 100%|██████████| 10/10 [00:00<00:00, 1247.82it/s, Mean reward=4.16, Mean PGN Loss=0.000587, Entropy=0.00205]\n",
      "Epoch #326: 100%|██████████| 10/10 [00:00<00:00, 1173.13it/s, Mean reward=4.16, Mean PGN Loss=0.000399, Entropy=0.00203]\n",
      "Epoch #327: 100%|██████████| 10/10 [00:00<00:00, 1110.40it/s, Mean reward=4.16, Mean PGN Loss=0.000233, Entropy=0.00201]\n",
      "Epoch #328: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.000132, Entropy=0.002]\n",
      "Epoch #329: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=4.16, Mean PGN Loss=0.000109, Entropy=0.00199]\n",
      "Epoch #330: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.000151, Entropy=0.00198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #331: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.000226, Entropy=0.00198]\n",
      "Epoch #332: 100%|██████████| 10/10 [00:00<00:00, 1000.14it/s, Mean reward=4.16, Mean PGN Loss=0.000299, Entropy=0.00197]\n",
      "Epoch #333: 100%|██████████| 10/10 [00:00<00:00, 1109.81it/s, Mean reward=4.16, Mean PGN Loss=0.00034, Entropy=0.00197]\n",
      "Epoch #334: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=0.000337, Entropy=0.00197]\n",
      "Epoch #335: 100%|██████████| 10/10 [00:00<00:00, 1250.28it/s, Mean reward=4.16, Mean PGN Loss=0.000293, Entropy=0.00196]\n",
      "Epoch #336: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=0.000225, Entropy=0.00196]\n",
      "Epoch #337: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=0.000155, Entropy=0.00196]\n",
      "Epoch #338: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=9.97e-5, Entropy=0.00196]\n",
      "Epoch #339: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=7.03e-5, Entropy=0.00195]\n",
      "Epoch #340: 100%|██████████| 10/10 [00:00<00:00, 1111.34it/s, Mean reward=4.16, Mean PGN Loss=6.68e-5, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #341: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=8.1e-5, Entropy=0.00195]\n",
      "Epoch #342: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=0.000101, Entropy=0.00195]\n",
      "Epoch #343: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=4.16, Mean PGN Loss=0.000115, Entropy=0.00195]\n",
      "Epoch #344: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=0.000117, Entropy=0.00195]\n",
      "Epoch #345: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=0.000106, Entropy=0.00195]\n",
      "Epoch #346: 100%|██████████| 10/10 [00:00<00:00, 1249.87it/s, Mean reward=4.16, Mean PGN Loss=8.41e-5, Entropy=0.00195]\n",
      "Epoch #347: 100%|██████████| 10/10 [00:00<00:00, 1250.46it/s, Mean reward=4.16, Mean PGN Loss=5.98e-5, Entropy=0.00195]\n",
      "Epoch #348: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=3.96e-5, Entropy=0.00195]\n",
      "Epoch #349: 100%|██████████| 10/10 [00:00<00:00, 1111.52it/s, Mean reward=4.16, Mean PGN Loss=2.78e-5, Entropy=0.00196]\n",
      "Epoch #350: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=4.16, Mean PGN Loss=2.54e-5, Entropy=0.00196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #351: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=3.02e-5, Entropy=0.00196]\n",
      "Epoch #352: 100%|██████████| 10/10 [00:00<00:00, 999.79it/s, Mean reward=4.16, Mean PGN Loss=3.82e-5, Entropy=0.00196] \n",
      "Epoch #353: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=4.5e-5, Entropy=0.00196]\n",
      "Epoch #354: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=4.75e-5, Entropy=0.00196]\n",
      "Epoch #355: 100%|██████████| 10/10 [00:00<00:00, 1250.39it/s, Mean reward=4.16, Mean PGN Loss=4.47e-5, Entropy=0.00196]\n",
      "Epoch #356: 100%|██████████| 10/10 [00:00<00:00, 1110.96it/s, Mean reward=4.16, Mean PGN Loss=3.76e-5, Entropy=0.00196]\n",
      "Epoch #357: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=2.85e-5, Entropy=0.00196]\n",
      "Epoch #358: 100%|██████████| 10/10 [00:00<00:00, 1249.76it/s, Mean reward=4.16, Mean PGN Loss=1.99e-5, Entropy=0.00196]\n",
      "Epoch #359: 100%|██████████| 10/10 [00:00<00:00, 908.94it/s, Mean reward=4.16, Mean PGN Loss=1.38e-5, Entropy=0.00196] \n",
      "Epoch #360: 100%|██████████| 10/10 [00:00<00:00, 1000.29it/s, Mean reward=4.16, Mean PGN Loss=1.09e-5, Entropy=0.00196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #361: 100%|██████████| 10/10 [00:00<00:00, 1111.57it/s, Mean reward=4.16, Mean PGN Loss=1.08e-5, Entropy=0.00196]\n",
      "Epoch #362: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=1.24e-5, Entropy=0.00195]\n",
      "Epoch #363: 100%|██████████| 10/10 [00:00<00:00, 1109.99it/s, Mean reward=4.16, Mean PGN Loss=1.4e-5, Entropy=0.00195]\n",
      "Epoch #364: 100%|██████████| 10/10 [00:00<00:00, 1249.64it/s, Mean reward=4.16, Mean PGN Loss=1.45e-5, Entropy=0.00195]\n",
      "Epoch #365: 100%|██████████| 10/10 [00:00<00:00, 1000.02it/s, Mean reward=4.16, Mean PGN Loss=1.35e-5, Entropy=0.00195]\n",
      "Epoch #366: 100%|██████████| 10/10 [00:00<00:00, 1249.68it/s, Mean reward=4.16, Mean PGN Loss=1.1e-5, Entropy=0.00195]\n",
      "Epoch #367: 100%|██████████| 10/10 [00:00<00:00, 1110.93it/s, Mean reward=4.16, Mean PGN Loss=7.84e-6, Entropy=0.00195]\n",
      "Epoch #368: 100%|██████████| 10/10 [00:00<00:00, 1110.84it/s, Mean reward=4.16, Mean PGN Loss=4.86e-6, Entropy=0.00195]\n",
      "Epoch #369: 100%|██████████| 10/10 [00:00<00:00, 1250.28it/s, Mean reward=4.16, Mean PGN Loss=2.76e-6, Entropy=0.00195]\n",
      "Epoch #370: 100%|██████████| 10/10 [00:00<00:00, 1110.84it/s, Mean reward=4.16, Mean PGN Loss=1.86e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #371: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=2.04e-6, Entropy=0.00195]\n",
      "Epoch #372: 100%|██████████| 10/10 [00:00<00:00, 999.43it/s, Mean reward=4.16, Mean PGN Loss=2.83e-6, Entropy=0.00195] \n",
      "Epoch #373: 100%|██████████| 10/10 [00:00<00:00, 1110.51it/s, Mean reward=4.16, Mean PGN Loss=3.69e-6, Entropy=0.00195]\n",
      "Epoch #374: 100%|██████████| 10/10 [00:00<00:00, 526.28it/s, Mean reward=4.16, Mean PGN Loss=4.14e-6, Entropy=0.00195]\n",
      "Epoch #375: 100%|██████████| 10/10 [00:00<00:00, 1000.02it/s, Mean reward=4.16, Mean PGN Loss=3.96e-6, Entropy=0.00195]\n",
      "Epoch #376: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=3.19e-6, Entropy=0.00195]\n",
      "Epoch #377: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=2.06e-6, Entropy=0.00195]\n",
      "Epoch #378: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=4.16, Mean PGN Loss=9.01e-7, Entropy=0.00195]\n",
      "Epoch #379: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=4.16, Mean PGN Loss=-5.64e-9, Entropy=0.00195]\n",
      "Epoch #380: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=-5.16e-7, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #381: 100%|██████████| 10/10 [00:00<00:00, 1249.83it/s, Mean reward=4.16, Mean PGN Loss=-6.44e-7, Entropy=0.00195]\n",
      "Epoch #382: 100%|██████████| 10/10 [00:00<00:00, 1000.24it/s, Mean reward=4.16, Mean PGN Loss=-5.23e-7, Entropy=0.00195]\n",
      "Epoch #383: 100%|██████████| 10/10 [00:00<00:00, 1111.49it/s, Mean reward=4.16, Mean PGN Loss=-3.41e-7, Entropy=0.00195]\n",
      "Epoch #384: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=4.16, Mean PGN Loss=-2.58e-7, Entropy=0.00195]\n",
      "Epoch #385: 100%|██████████| 10/10 [00:00<00:00, 1111.02it/s, Mean reward=4.16, Mean PGN Loss=-3.6e-7, Entropy=0.00195]\n",
      "Epoch #386: 100%|██████████| 10/10 [00:00<00:00, 1249.76it/s, Mean reward=4.16, Mean PGN Loss=-6.33e-7, Entropy=0.00195]\n",
      "Epoch #387: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=-9.96e-7, Entropy=0.00195]\n",
      "Epoch #388: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=4.16, Mean PGN Loss=-1.34e-6, Entropy=0.00195]\n",
      "Epoch #389: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=4.16, Mean PGN Loss=-1.58e-6, Entropy=0.00195]\n",
      "Epoch #390: 100%|██████████| 10/10 [00:00<00:00, 1111.02it/s, Mean reward=4.16, Mean PGN Loss=-1.67e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #391: 100%|██████████| 10/10 [00:00<00:00, 1110.84it/s, Mean reward=4.16, Mean PGN Loss=-1.61e-6, Entropy=0.00195]\n",
      "Epoch #392: 100%|██████████| 10/10 [00:00<00:00, 1000.19it/s, Mean reward=4.16, Mean PGN Loss=-1.48e-6, Entropy=0.00195]\n",
      "Epoch #393: 100%|██████████| 10/10 [00:00<00:00, 1111.52it/s, Mean reward=4.16, Mean PGN Loss=-1.35e-6, Entropy=0.00195]\n",
      "Epoch #394: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=-1.27e-6, Entropy=0.00195]\n",
      "Epoch #395: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=-1.28e-6, Entropy=0.00195]\n",
      "Epoch #396: 100%|██████████| 10/10 [00:00<00:00, 1000.38it/s, Mean reward=4.16, Mean PGN Loss=-1.38e-6, Entropy=0.00195]\n",
      "Epoch #397: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=-1.52e-6, Entropy=0.00195]\n",
      "Epoch #398: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=-1.67e-6, Entropy=0.00195]\n",
      "Epoch #399: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=-1.79e-6, Entropy=0.00195]\n",
      "Epoch #400: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=-1.86e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #401: 100%|██████████| 10/10 [00:00<00:00, 1250.61it/s, Mean reward=4.16, Mean PGN Loss=-1.88e-6, Entropy=0.00195]\n",
      "Epoch #402: 100%|██████████| 10/10 [00:00<00:00, 1109.81it/s, Mean reward=4.16, Mean PGN Loss=-1.87e-6, Entropy=0.00195]\n",
      "Epoch #403: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=4.16, Mean PGN Loss=-1.85e-6, Entropy=0.00195]\n",
      "Epoch #404: 100%|██████████| 10/10 [00:00<00:00, 1111.34it/s, Mean reward=4.16, Mean PGN Loss=-1.84e-6, Entropy=0.00195]\n",
      "Epoch #405: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=-1.85e-6, Entropy=0.00195]\n",
      "Epoch #406: 100%|██████████| 10/10 [00:00<00:00, 769.13it/s, Mean reward=4.16, Mean PGN Loss=-1.87e-6, Entropy=0.00195]\n",
      "Epoch #407: 100%|██████████| 10/10 [00:00<00:00, 588.33it/s, Mean reward=4.16, Mean PGN Loss=-1.91e-6, Entropy=0.00195]\n",
      "Epoch #408: 100%|██████████| 10/10 [00:00<00:00, 833.56it/s, Mean reward=4.16, Mean PGN Loss=-1.94e-6, Entropy=0.00195]\n",
      "Epoch #409: 100%|██████████| 10/10 [00:00<00:00, 769.33it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #410: 100%|██████████| 10/10 [00:00<00:00, 1111.55it/s, Mean reward=4.16, Mean PGN Loss=-1.94e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #411: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=4.16, Mean PGN Loss=-1.92e-6, Entropy=0.00195]\n",
      "Epoch #412: 100%|██████████| 10/10 [00:00<00:00, 999.91it/s, Mean reward=4.16, Mean PGN Loss=-1.89e-6, Entropy=0.00195]\n",
      "Epoch #413: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=-1.86e-6, Entropy=0.00195]\n",
      "Epoch #414: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=-1.85e-6, Entropy=0.00195]\n",
      "Epoch #415: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=-1.86e-6, Entropy=0.00195]\n",
      "Epoch #416: 100%|██████████| 10/10 [00:00<00:00, 1110.90it/s, Mean reward=4.16, Mean PGN Loss=-1.88e-6, Entropy=0.00195]\n",
      "Epoch #417: 100%|██████████| 10/10 [00:00<00:00, 1111.04it/s, Mean reward=4.16, Mean PGN Loss=-1.9e-6, Entropy=0.00195]\n",
      "Epoch #418: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=-1.92e-6, Entropy=0.00195]\n",
      "Epoch #419: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=-1.94e-6, Entropy=0.00195]\n",
      "Epoch #420: 100%|██████████| 10/10 [00:00<00:00, 1249.83it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #421: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #422: 100%|██████████| 10/10 [00:00<00:00, 1249.61it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #423: 100%|██████████| 10/10 [00:00<00:00, 1000.02it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #424: 100%|██████████| 10/10 [00:00<00:00, 1000.26it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #425: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #426: 100%|██████████| 10/10 [00:00<00:00, 1250.39it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #427: 100%|██████████| 10/10 [00:00<00:00, 999.50it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195] \n",
      "Epoch #428: 100%|██████████| 10/10 [00:00<00:00, 1250.35it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #429: 100%|██████████| 10/10 [00:00<00:00, 1110.87it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #430: 100%|██████████| 10/10 [00:00<00:00, 1111.63it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #431: 100%|██████████| 10/10 [00:00<00:00, 1111.40it/s, Mean reward=4.16, Mean PGN Loss=-1.94e-6, Entropy=0.00195]\n",
      "Epoch #432: 100%|██████████| 10/10 [00:00<00:00, 1110.90it/s, Mean reward=4.16, Mean PGN Loss=-1.93e-6, Entropy=0.00195]\n",
      "Epoch #433: 100%|██████████| 10/10 [00:00<00:00, 1111.37it/s, Mean reward=4.16, Mean PGN Loss=-1.93e-6, Entropy=0.00195]\n",
      "Epoch #434: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=4.16, Mean PGN Loss=-1.93e-6, Entropy=0.00195]\n",
      "Epoch #435: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=-1.93e-6, Entropy=0.00195]\n",
      "Epoch #436: 100%|██████████| 10/10 [00:00<00:00, 1111.19it/s, Mean reward=4.16, Mean PGN Loss=-1.93e-6, Entropy=0.00195]\n",
      "Epoch #437: 100%|██████████| 10/10 [00:00<00:00, 1249.72it/s, Mean reward=4.16, Mean PGN Loss=-1.94e-6, Entropy=0.00195]\n",
      "Epoch #438: 100%|██████████| 10/10 [00:00<00:00, 1111.02it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #439: 100%|██████████| 10/10 [00:00<00:00, 1428.29it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #440: 100%|██████████| 10/10 [00:00<00:00, 1110.34it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #441: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #442: 100%|██████████| 10/10 [00:00<00:00, 1000.26it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #443: 100%|██████████| 10/10 [00:00<00:00, 1250.46it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #444: 100%|██████████| 10/10 [00:00<00:00, 1250.31it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #445: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #446: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #447: 100%|██████████| 10/10 [00:00<00:00, 1250.24it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #448: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #449: 100%|██████████| 10/10 [00:00<00:00, 1110.81it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #450: 100%|██████████| 10/10 [00:00<00:00, 1110.31it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #451: 100%|██████████| 10/10 [00:00<00:00, 1250.20it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #452: 100%|██████████| 10/10 [00:00<00:00, 1110.93it/s, Mean reward=4.16, Mean PGN Loss=-1.94e-6, Entropy=0.00195]\n",
      "Epoch #453: 100%|██████████| 10/10 [00:00<00:00, 1250.20it/s, Mean reward=4.16, Mean PGN Loss=-1.94e-6, Entropy=0.00195]\n",
      "Epoch #454: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #455: 100%|██████████| 10/10 [00:00<00:00, 999.83it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195] \n",
      "Epoch #456: 100%|██████████| 10/10 [00:00<00:00, 1111.43it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #457: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #458: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #459: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #460: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #461: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #462: 100%|██████████| 10/10 [00:00<00:00, 999.74it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195] \n",
      "Epoch #463: 100%|██████████| 10/10 [00:00<00:00, 1111.40it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #464: 100%|██████████| 10/10 [00:00<00:00, 1250.28it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #465: 100%|██████████| 10/10 [00:00<00:00, 1250.02it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #466: 100%|██████████| 10/10 [00:00<00:00, 1249.87it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #467: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #468: 100%|██████████| 10/10 [00:00<00:00, 1250.05it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #469: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #470: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #471: 100%|██████████| 10/10 [00:00<00:00, 1249.98it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #472: 100%|██████████| 10/10 [00:00<00:00, 1000.14it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #473: 100%|██████████| 10/10 [00:00<00:00, 1250.20it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #474: 100%|██████████| 10/10 [00:00<00:00, 1250.13it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #475: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #476: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #477: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #478: 100%|██████████| 10/10 [00:00<00:00, 1249.83it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #479: 100%|██████████| 10/10 [00:00<00:00, 1111.34it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #480: 100%|██████████| 10/10 [00:00<00:00, 1248.27it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #481: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #482: 100%|██████████| 10/10 [00:00<00:00, 1051.20it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #483: 100%|██████████| 10/10 [00:00<00:00, 1250.17it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #484: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #485: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #486: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #487: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #488: 100%|██████████| 10/10 [00:00<00:00, 1111.13it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #489: 100%|██████████| 10/10 [00:00<00:00, 1111.07it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #490: 100%|██████████| 10/10 [00:00<00:00, 1051.63it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #491: 100%|██████████| 10/10 [00:00<00:00, 1111.25it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #492: 100%|██████████| 10/10 [00:00<00:00, 999.91it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195] \n",
      "Epoch #493: 100%|██████████| 10/10 [00:00<00:00, 1111.31it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #494: 100%|██████████| 10/10 [00:00<00:00, 1111.22it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #495: 100%|██████████| 10/10 [00:00<00:00, 1250.31it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #496: 100%|██████████| 10/10 [00:00<00:00, 1249.94it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #497: 100%|██████████| 10/10 [00:00<00:00, 1250.09it/s, Mean reward=4.16, Mean PGN Loss=-1.95e-6, Entropy=0.00195]\n",
      "Epoch #498: 100%|██████████| 10/10 [00:00<00:00, 1111.10it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #499: 100%|██████████| 10/10 [00:00<00:00, 1110.90it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]\n",
      "Epoch #500: 100%|██████████| 10/10 [00:00<00:00, 1111.28it/s, Mean reward=4.16, Mean PGN Loss=-1.96e-6, Entropy=0.00195]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "start_time = time.time()\n",
    "time_shift = 0 if len(log_data[\"Time\"]) == 0 else log_data[\"Time\"][-1]\n",
    "epoch_shift = 0 if len(log_data[\"Epoch\"]) == 0 else log_data[\"Epoch\"][-1]\n",
    "\n",
    "statistics_deleted_dicts = []\n",
    "best_info_dict = {}\n",
    "\n",
    "pgn.train()\n",
    "for i in range(1 + epoch_shift, 1 + EPOCHS):\n",
    "    state = env.reset()\n",
    "    buffer = TrajectoryBuffer()\n",
    "    env_states_buf, env_rew_act_buf = [], []\n",
    "    ep_rewards = []\n",
    "    done_episodes = 0\n",
    "\n",
    "    train_rewards = []\n",
    "    train_ep_len = []\n",
    "    statistics_dicts = []\n",
    "\n",
    "    epoch_loop = tqdm(total=EPISODES_BATCH, desc=f\"Epoch #{i}\", position=0)\n",
    "\n",
    "    while done_episodes < EPISODES_BATCH:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32, device=DEVICE)\n",
    "            action_logits = pgn(state_tensor)[0]\n",
    "\n",
    "        action = agent.choose_action(action_logits)\n",
    "        state2, reward, done = env.step(action)\n",
    "\n",
    "        env_states_buf.append(copy(state))\n",
    "        env_rew_act_buf.append([reward, int(action)])\n",
    "\n",
    "        state = copy(state2)\n",
    "\n",
    "        ep_rewards.append(reward)\n",
    "\n",
    "        if done:\n",
    "            buffer.store(\n",
    "                np.array(env_states_buf),\n",
    "                np.array(env_rew_act_buf),\n",
    "            )\n",
    "            env_states_buf, env_rew_act_buf = [], []\n",
    "\n",
    "            train_rewards.append(np.sum(ep_rewards))\n",
    "            train_ep_len.append(len(ep_rewards))\n",
    "\n",
    "            state = env.reset()\n",
    "            ep_rewards = []\n",
    "            done_episodes += 1\n",
    "            epoch_loop.update(1)\n",
    "\n",
    "    state_batch, action_batch, reward_batch = buffer.get_batch()\n",
    "\n",
    "    # Update PGN\n",
    "    pgn_optimizer.zero_grad()\n",
    "    states_t = torch.FloatTensor(np.array(state_batch)).to(DEVICE)\n",
    "    batch_actions_t = torch.LongTensor(action_batch).to(DEVICE)\n",
    "    batch_cum_rewards_t = torch.FloatTensor(reward_batch).to(DEVICE)\n",
    "\n",
    "    logits_v, value_v = pgn(states_t)\n",
    "\n",
    "    # Value loss\n",
    "    loss_value_v = F.mse_loss(value_v.squeeze(-1), batch_cum_rewards_t)\n",
    "\n",
    "    # Policy loss\n",
    "    log_prob_v = F.log_softmax(logits_v, dim=1)\n",
    "    adv_v = batch_cum_rewards_t - value_v.detach()\n",
    "    log_prob_actions_v = adv_v * log_prob_v[range(len(states_t)), batch_actions_t]\n",
    "    loss_policy_v = -log_prob_actions_v.mean()\n",
    "\n",
    "    # Entropy loss\n",
    "    prob_v = F.softmax(logits_v, dim=1)\n",
    "    entropy_v = (prob_v * log_prob_v).sum(dim=1).mean()\n",
    "    entropy_loss_v = ENTROPY_BETA * entropy_v\n",
    "\n",
    "    # Policy backward\n",
    "    loss_policy_v.backward(retain_graph=True)\n",
    "\n",
    "    # Value backward\n",
    "    loss_v = entropy_loss_v + loss_value_v\n",
    "    loss_v.backward()\n",
    "\n",
    "    if PGN_CLIP_GRAD > 0:\n",
    "        nn.utils.clip_grad_norm_(pgn.parameters(), PGN_CLIP_GRAD)\n",
    "    pgn_optimizer.step()\n",
    "\n",
    "    loss_v += loss_policy_v\n",
    "\n",
    "    # logging\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time = time.time() - start_time + time_shift\n",
    "\n",
    "    if len(statistics_dicts) > 0:\n",
    "        for k in statistics_dicts[0]:\n",
    "            statistics[k].append(np.mean([d[k] for d in statistics_dicts]))\n",
    "\n",
    "    log_data[\"Epoch\"].append(i)\n",
    "    log_data[\"Time\"].append(elapsed_time)\n",
    "    log_data[\"Mean Reward\"].append(np.mean(train_rewards))\n",
    "    log_data[\"Mean Episode Length\"].append(np.mean(train_ep_len))\n",
    "    log_data[\"Mean PGN Loss\"].append(loss_v.item())\n",
    "    log_data[\"Mean PGN Policy Loss\"].append(loss_policy_v.item())\n",
    "    log_data[\"Mean PGN Value Loss\"].append(loss_value_v.item())\n",
    "    log_data[\"Entropy\"].append(-entropy_v.item())\n",
    "\n",
    "    epoch_loop.set_postfix(\n",
    "        {\n",
    "            \"Mean reward\": log_data[\"Mean Reward\"][-1],\n",
    "            \"Mean PGN Loss\": log_data[\"Mean PGN Loss\"][-1],\n",
    "            \"Entropy\": log_data[\"Entropy\"][-1],\n",
    "        }\n",
    "    )\n",
    "    epoch_loop.close()\n",
    "\n",
    "    evaluate\n",
    "    if i % EVAL_PERIOD == 0 or i == EPOCHS:\n",
    "        evaluate(\n",
    "            pgn, agent, env\n",
    "        )\n",
    "        pgn.train()\n",
    "\n",
    "        # logging\n",
    "        # mean_test_loss = np.mean(test_losses)\n",
    "        # log_data[\"Mean Test Loss\"].append(mean_test_loss)\n",
    "        # log_data[\"Eval Epoch\"].append(i)\n",
    "        # log_data[\"Eval Time\"].append(elapsed_time)\n",
    "\n",
    "    # # log\n",
    "    # if i % LOG_PERIOD == 0 or i == EPOCHS:\n",
    "        \n",
    "    #     ## plots\n",
    "    #     LOGGER.save(\n",
    "    #         \"\",\n",
    "    #         \"plots\",\n",
    "    #         {\n",
    "    #             \"Epoch\": log_data[\"Epoch\"],\n",
    "    #             \"Time\": log_data[\"Time\"],\n",
    "    #             \"Eval Epoch\": log_data[\"Eval Epoch\"],\n",
    "    #             \"Eval Time\": log_data[\"Eval Time\"],\n",
    "    #             \"Mean Reward\": moving_average(log_data[\"Mean Reward\"]),\n",
    "    #             \"Mean PGN Policy Loss\": moving_average(log_data[\"Mean PGN Policy Loss\"]),\n",
    "    #             \"Mean PGN Value Loss\": moving_average(log_data[\"Mean PGN Value Loss\"]),\n",
    "    #             \"Mean PGN Loss\": moving_average(log_data[\"Mean PGN Loss\"]),\n",
    "    #             \"Mean Test Loss\": log_data[\"Mean Test Loss\"],\n",
    "    #         },\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1b96b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m plots_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Test Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Test Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     13\u001b[0m plots \u001b[38;5;241m=\u001b[39m LOGGER\u001b[38;5;241m.\u001b[39mlog_plots\n\u001b[1;32m---> 15\u001b[0m \u001b[43mdraw_plots\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplots_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_plots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 120\u001b[0m, in \u001b[0;36mdraw_plots\u001b[1;34m(data_dict, plots, title, ylim, row_plots, plot_width, plot_height, use_rainbow, use_common_legend, adjust)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_plots\u001b[39m(\n\u001b[0;32m    109\u001b[0m     data_dict: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m    110\u001b[0m     plots: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mdict\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     adjust: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    119\u001b[0m ):\n\u001b[1;32m--> 120\u001b[0m     \u001b[43mget_plots\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mylim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_plots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_rainbow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_common_legend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43madjust\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[5], line 69\u001b[0m, in \u001b[0;36mget_plots\u001b[1;34m(data_dict, plots, title, ylim, row_plots, plot_width, plot_height, use_rainbow, use_common_legend, adjust)\u001b[0m\n\u001b[0;32m     67\u001b[0m     y_values \u001b[38;5;241m=\u001b[39m data_dict[p2\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m p2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     68\u001b[0m     ax\u001b[38;5;241m.\u001b[39mplot(x_values, y_values, label\u001b[38;5;241m=\u001b[39mp2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 69\u001b[0m     ax\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mx_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, y_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p2v \u001b[38;5;129;01min\u001b[39;00m p2vs:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots_data = {\n",
    "    \"Epoch\": log_data[\"Epoch\"],\n",
    "    \"Time\": log_data[\"Time\"],\n",
    "    \"Eval Epoch\": log_data[\"Eval Epoch\"],\n",
    "    \"Eval Time\": log_data[\"Eval Time\"],\n",
    "    \"Mean Reward\": moving_average(log_data[\"Mean Reward\"]),\n",
    "    \"Mean PGN Loss\": moving_average(log_data[\"Mean PGN Loss\"]),\n",
    "    \"Mean PGN Policy Loss\": moving_average(log_data[\"Mean PGN Policy Loss\"]),\n",
    "    \"Mean PGN Value Loss\": moving_average(log_data[\"Mean PGN Value Loss\"]),\n",
    "    \"Mean Test Loss\": log_data[\"Mean Test Loss\"],\n",
    "}\n",
    "\n",
    "plots = LOGGER.log_plots\n",
    "\n",
    "draw_plots(\n",
    "    plots_data,\n",
    "    plots,\n",
    "    plot_width=8,\n",
    "    plot_height=4,\n",
    "    row_plots=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5ab97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
